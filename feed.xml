<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://fooyuhui.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://fooyuhui.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-11T04:31:59+00:00</updated><id>https://fooyuhui.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">DEXTERITYGEN Foundation Controller for Unprecedented Dexterity</title><link href="https://fooyuhui.github.io/blog/2025/dex_gen/" rel="alternate" type="text/html" title="DEXTERITYGEN Foundation Controller for Unprecedented Dexterity"/><published>2025-02-10T00:00:00+00:00</published><updated>2025-02-10T00:00:00+00:00</updated><id>https://fooyuhui.github.io/blog/2025/dex_gen</id><content type="html" xml:base="https://fooyuhui.github.io/blog/2025/dex_gen/"><![CDATA[<blockquote> <p>Takeaway: DexGen is a generative model that can translate an unsafe, coarse motion command produced by external policy to safe and fine actions.</p> </blockquote> <h2 id="insight">Insight</h2> <p>To achieve effective teleoperation for a dexterous hand, merely retargeting hand motion is insufficient. We can use RL to pretrain large-scale dexterous motion primitives, and then roll out some data using this policy to train a dexterous foundational controller.</p> <h2 id="method">Method</h2> <h5 id="large-scale-behavior-dataset-generation">Large-Scale Behavior Dataset Generation.</h5> <ol> <li>Generate a set of object grasps using Grasp Analysis and Rapidly-exploring Random Tree (RRT). Each generated grasp is defined as a tuple (hand joint position, object pose). (over 100K grasp)</li> <li>Train a anygrasp-to-anygrasp policy using RL. We set the goal to be a randomly selected nearby grasp using k nearest-neighbor search. (The authors also introduce other tasks besides anygrasp-to-anygrasp, such fine-grained manipulation and free finger moving etc.)</li> <li>Use this anygrasp-to-anygrasp policy to rollout grasp transition sequences to cover all the possible hand-object interation modes. ($1 \times 10^{10}$ transitions)</li> </ol> <h5 id="dexgen-model">DexGen Model</h5> <p>Two modules: a diffusion model and a inverse dynamics model.</p> <ol> <li>Diffusion Model: given robot state and a mode conditioning variable, characterize the distribution of robot finger keypoint motions. (3D keypoint motions $\Delta x \in \mathbb{R}^{T \times K \times 3}$, $T$ is the future horizon, $K$ is the number of keypoints)</li> <li>Inverse Dynamics Model: given the current observation and the future keypoints, predict the executable actions.</li> </ol> <p>The whole system takes robot state, external motion conditioning, and mode conditioning as input.</p> <p>The motion conditioning is not fed into the diffusion model directly but as the gradient guidance during the diffusion sampling.</p> <h5 id="inference-motion-conditioning-with-guided-sampling">Inference: Motion Conditioning with Guided Sampling</h5> <p>The goal is to sample a keypoint motion that is both safe and maximally preserve the input reference motion.</p> <p>We can use the following formula to sample the keypoint motion:</p> \[\Delta x \sim p_\theta(\Delta x \mid o)\mathrm{exp}(-\mathrm{Dist}(\Delta x, \Delta x_{\text{input}}))\] <p>Here, $\Delta x_{\text{input}}$ is the input commanded fingertip offset, and $\mathrm{Dist}$ is a distance metric.</p> <p>Since the action of the robot hand has a high degree of freedom, naive sampling strategies become computationally intractable. The authors propose using gradient guidance in the diffusion sampling process to incorporate motion conditioning. In each diffusion step, we adjust the denoised sample $\Delta x$ by subtracting $\alpha\sum\nabla_{\Delta x}\text{Dist}(\Delta x, \Delta x_\text{input})$ as a guide. Here $\alpha$ is a parameter of the strength of the guidance to be tuned.</p> <h2 id="conclusion">Conclusion</h2> <p>The authors demonstrate that DexGen can effectively translate unsafe, coarse motion commands to safe and fine actions. The model can be used in a teleoperation setting to improve the dexterity of the robot hand.</p>]]></content><author><name></name></author><category term="paper-reading"/><category term="robotics"/><summary type="html"><![CDATA[DexGen Reading Notes]]></summary></entry></feed>